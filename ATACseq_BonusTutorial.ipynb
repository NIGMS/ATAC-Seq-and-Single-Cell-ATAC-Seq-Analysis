{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3494e2-09a4-4688-9377-648fe84722e4",
   "metadata": {},
   "source": [
    "# ATAC-seq Bonus Submodule: Tutorial 1 with custom data\n",
    "\n",
    "<img src=\"./Tutorial1/LessonImages/ATACseqWorkflowLesson1.jpg\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "## Overview & Purpose\n",
    "In this notebook, we are going to explore how to run this module with a new dataset. These submodules provide a great framework for running a rigorous and scalable ATAC-Seq analysis, but there are some considerations that must be made in order to run this with your own data. We will walk through that process here so that hopefully, you are able to take these notebooks to your research group and use them for your own analysis. Notice that we do not give you all the answers in the code blocks, but if you get stuck, use the dropdowns for help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc2106-27ba-4bd5-9cc6-9aed1024d615",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 1: Set Up Environment\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79377125-147a-458e-ba42-3aa9ed6693dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 82.9M  100 82.9M    0     0   116M      0 --:--:-- --:--:-- --:--:--  223M\n",
      "ERROR: File or directory already exists: '/home/jupyter/mambaforge'\n",
      "If you want to update an existing installation, use the -u option.\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "!bash Mambaforge-$(uname)-$(uname -m).sh -b -p $HOME/mambaforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a3898e-8f0f-4fc7-9ec0-5f9fb470addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mamba to your path\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/mambaforge/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b87bee4-7276-4c30-ac84-3b6f4af9e0ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (1.4.1) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['fastqc', 'bowtie2', 'picard', 'multiqc', 'samtools', 'trimmomatic']\n",
      "\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpkgs/main/linux-64                                            No change\n",
      "pkgs/main/noarch                                              No change\n",
      "pkgs/r/linux-64                                               No change\n",
      "pkgs/r/noarch                                                 No change\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "numthreads=!lscpu | grep '^CPU(s)'| awk '{print $2-1}'\n",
    "numthreadsint = int(numthreads[0])\n",
    "! mamba install -c bioconda fastqc bowtie2 picard multiqc samtools trimmomatic  -y\n",
    "! pip install jupyterquiz==2.0.7 jupytercards jupyter-book>=0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a10943-42b7-4871-819f-cbcc65b2a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "from jupytercards import display_flashcards\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae2a63-1f7d-49ec-a919-c5954e906537",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 2: Get new fastq data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b0313-dbb9-4f0b-b6db-11f02ffe15ac",
   "metadata": {},
   "source": [
    "We are going to pull a new dataset from SRA. In this example, we are going to use data from an experiment that compared cis-regulatory elements across tissues in zebrafish. The BioProject ID is [PRJNA553572](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA553572). There are over 200 samples in this experiment, but for simplicity, we are only going to use one liver sample and one muscle sample. The accession numbers for these samples are SRR12173474 and SRR12173476. To learn how to pull data from SRA, we recommend you consult the [STRIDES tutorial on SRA downloads](https://github.com/STRIDES/NIHCloudLabGCP/blob/main/tutorials/notebooks/SRADownload/SRA-Download.ipynb). For this situation, we have already pulled the data from SRA and have it in our storage bucket, so we will copy it to our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0aa900e-e4b3-4239-b4d1-897c3977e071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/InputFiles/Liver_sub_1.fastq.gz...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/InputFiles/Liver_sub_2.fastq.gz...\n",
      "- [2/2 files][418.5 MiB/418.5 MiB] 100% Done                                    \n",
      "Operation completed over 2 objects/418.5 MiB.                                    \n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/InputFiles/Muscle_sub_1.fastq.gz...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/InputFiles/Muscle_sub_2.fastq.gz...\n",
      "\\ [2/2 files][574.7 MiB/574.7 MiB] 100% Done  58.4 MiB/s ETA 00:00:00           \n",
      "Operation completed over 2 objects/574.7 MiB.                                    \n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.3.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.4.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.rev.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.rev.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/NexteraPE.fa...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.3.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.4.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.fa...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.rev.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.rev.2.bt2...\n",
      "\\ [14/15 files][  2.7 GiB/  2.7 GiB]  99% Done  84.2 MiB/s ETA 00:00:00         \r"
     ]
    }
   ],
   "source": [
    "# These commands create our directory structure.\n",
    "! mkdir -p Tutorial1/InputFiles\n",
    "! mkdir -p Tutorial1/QC\n",
    "! mkdir -p Tutorial1/Trimmed\n",
    "! mkdir -p Tutorial1/Mapped\n",
    "! mkdir -p Tutorial1/RefGenome\n",
    "\n",
    "# These commands help identify the Google Cloud Storage bucket where the example files are held.\n",
    "original_bucket = \"gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7bccb-eb4a-41ad-883e-4a11f44820c2",
   "metadata": {},
   "source": [
    "Now copy the input data from the Cloud Storage Bucket to your local Tutorial1/InputFiles directory.\n",
    "The original fastq files were very large, so here we are using down-sampled versions that contain 10% of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e5175f-514f-43e6-91ac-a3dbf955f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
      "/bin/bash: -c: line 1: ` <YOUR COMMAND HERE>'\n"
     ]
    }
   ],
   "source": [
    "! <YOUR COMMAND HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113d532-c940-4725-9327-73709bb766ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for help</summary>\n",
    "    \n",
    "  Make sure you include the `!` in front of your command! \n",
    "    \n",
    "  ```  \n",
    "gsutil -m cp $original_bucket/InputFiles/Liver* Tutorial1/InputFiles/\n",
    "gsutil -m cp $original_bucket/InputFiles/Muscle* Tutorial1/InputFiles/\n",
    "  ```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9945799-12e6-4f01-a156-ef7b27cd7874",
   "metadata": {},
   "source": [
    "Now copy the reference genome from the Cloud Storage Bucket to your local Tutorial1/RefGenome directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7468826-ba85-40d2-ba3c-e023ef1c2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! <YOUR COMMAND HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880018d4-49f4-4fa6-a5bf-56c390aa8939",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for help</summary>\n",
    "    \n",
    "  ```  \n",
    "gsutil -m cp $original_bucket/RefGenome/* Tutorial1/RefGenome\n",
    "  ```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bece6ccb-e7cd-4dbe-a37b-d19fe4ddc38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.3.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.4.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.rev.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/GRCz11.rev.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/NexteraPE.fa...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.3.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.2.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.fa...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.rev.1.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.4.bt2...\n",
      "Copying gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1/RefGenome/hg38chr4.rev.2.bt2...\n",
      "\\ [14/15 files][  2.7 GiB/  2.7 GiB]  99% Done  60.4 MiB/s ETA 00:00:00         \r"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp $original_bucket/RefGenome/* Tutorial1/RefGenome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a6725-8d17-42d3-9b83-99f166fd369b",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 3: QC\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f91cb-944a-43ae-b15c-25fc08b164e9",
   "metadata": {},
   "source": [
    "Now run fastqc on your data. You can use the the wildcard \\*.fastq.gz to find the files like this: Tutorial1/InputFiles/*fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83bd911-d188-46a9-82a2-a4e09d78fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
      "/bin/bash: -c: line 1: ` <YOUR COMMAND HERE>'\n"
     ]
    }
   ],
   "source": [
    "# This command runs fastqc on each fastq.gz file inside our InputFiles directory and stores the ouput reports in our QC directory.\n",
    "! <YOUR COMMAND HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04976ca-829c-4936-bc85-b5ac80c9f86a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for help</summary>\n",
    "    \n",
    "  ```  \n",
    "  fastqc -t $numthreadsint -q -o Tutorial1/QC Tutorial1/InputFiles/*fastq.gz\n",
    "  ```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c2cd7-7756-4894-8ff5-290beaf5a40c",
   "metadata": {},
   "source": [
    "We then use multiqc to summarize the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ae4f1-e10b-4e93-8bfa-d0d38b1857c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! <YOUR COMMAND HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea287189-5f7e-4f47-ac62-65e15c00b0c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click for help</summary>\n",
    "    \n",
    "  ```  \n",
    "  multiqc -o Tutorial1/QC -f Tutorial1/QC 2> Tutorial1/QC/multiqc_log.txt\n",
    "  ```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1686f88-3c20-464b-a3f3-884d7c830478",
   "metadata": {},
   "outputs": [],
   "source": [
    "! multiqc -o Tutorial1/QC -f Tutorial1/QC 2> Tutorial1/QC/multiqc_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5fe12-e427-4e26-8fe6-0d1a680f63e5",
   "metadata": {},
   "source": [
    "We'll load the outputs into a pandas data frame , but fastqc also produces an html report that you can browse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62933a61-725e-4ff1-b31b-1bf2d8f7bd38",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tutorial1/QC/multiqc_data/multiqc_fastqc.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTutorial1/QC/multiqc_data/multiqc_fastqc.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m display(dframe)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tutorial1/QC/multiqc_data/multiqc_fastqc.txt'"
     ]
    }
   ],
   "source": [
    "# We'll load this into a pandas table to work in this context, but fastqc also produces an html report that you can browse.\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_fastqc.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f6fa-f59f-4ed4-b5ec-ea10935bcdbe",
   "metadata": {},
   "source": [
    "As we come to the trimming step, we need to make some changes. As written, the notebook calls CTL and MUTANT, but our new samples are named Liver and Muslce. We will change the command to Liver and Muscle respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ed53f-d391-4077-954e-625464dfb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this cell, we have replaced CTL with Liver.\n",
    "\n",
    "# This will trim off N's as well as nextera adapters present in ATAC-seq library preparation. Placing the trimmed reads in our Trimmed folder.\n",
    "!trimmomatic PE -threads $numthreadsint Tutorial1/InputFiles/Liver_sub_1.fastq.gz Tutorial1/InputFiles/Liver_sub_2.fastq.gz Tutorial1/Trimmed/Liver_trimmed_R1.fastq.gz Tutorial1/Trimmed/Liver_unpaired_R1.fastq.gz Tutorial1/Trimmed/Liver_trimmed_R2.fastq.gz Tutorial1/Trimmed/Liver_unpaired_R2.fastq.gz ILLUMINACLIP:Tutorial1/RefGenome/NexteraPE.fa:2:30:10 LEADING:3 TRAILING:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f0191-68d9-4b0a-94ce-e601b9ce693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this cell, we have replaced MUTANT with Muscle.\n",
    "\n",
    "# This will trim off N's as well as nextera adapters present in ATAC-seq library preparation. Placing the trimmed reads in our Trimmed folder.\n",
    "!trimmomatic PE -threads $numthreadsint Tutorial1/InputFiles/Muscle_sub_1.fastq.gz Tutorial1/InputFiles/Muscle_sub_2.fastq.gz Tutorial1/Trimmed/Muscle_trimmed_R1.fastq.gz Tutorial1/Trimmed/Muscle_unpaired_R1.fastq.gz Tutorial1/Trimmed/Muscle_trimmed_R2.fastq.gz Tutorial1/Trimmed/Muscle_unpaired_R2.fastq.gz ILLUMINACLIP:Tutorial1/RefGenome/NexteraPE.fa:2:30:10 LEADING:3 TRAILING:3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f4abe-c217-46bf-b41d-0284efe57c9c",
   "metadata": {},
   "source": [
    "The summary step can proceed as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1d39e-4e92-4708-9fa2-dad49cbd3b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fastqc -t $numthreadsint -q -o Tutorial1/Trimmed Tutorial1/Trimmed/*fastq.gz\n",
    "!multiqc -o Tutorial1/QC -f Tutorial1/Trimmed 2> Tutorial1/QC/multiqc_log.txt\n",
    "\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_general_stats.txt\", sep='\\t')\n",
    "display(dframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c0ee9a-c08b-4530-a319-25e609464b1a",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 4: Mapping\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82294e-dad4-47f8-b44e-11d089d3d53d",
   "metadata": {},
   "source": [
    "The most important change we need to make in the mapping step is the reference genome. Our original notebook was based on human sequences, but our new dataset is comprised of zebrafish sequences. We will use the GRCz11 reference genome. We have already stored it in our storage bucket, but you can easily get bowtie2 reference genomes for several common organisms [here](https://benlangmead.github.io/aws-indexes/bowtie). Simply put the .bt2 files in your reference genome directory. We can confirm that we have downloaded them in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929031c-5489-4ad0-9db7-03e5b965acb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls Tutorial1/RefGenome/*bt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402b428-879e-4546-8e60-572c8bc3ed40",
   "metadata": {},
   "source": [
    "Next we will run the bowtie2 mapping step using the GRCz11 .bt2 reference files. As with above, we need to make the appropriate changes from CTL and MUTANT to our tissues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f2937-f9df-4cad-9b07-22265fad888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: The -x option specifies the prefix of the index. -1 specifies our left-end trimmed reads file. -2 specifies our right-end trimmed reads file. -S specifies our output file in sam format.\n",
    "!bowtie2 -p $numthreadsint -x Tutorial1/RefGenome/GRCz11 -1 Tutorial1/Trimmed/Liver_trimmed_R1.fastq.gz -2 Tutorial1/Trimmed/Liver_trimmed_R2.fastq.gz -S Tutorial1/Mapped/Liver.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fb88c-aa9e-435a-a4bf-f0774d6b1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same thing for our other sample.\n",
    "!bowtie2 -p $numthreadsint -x Tutorial1/RefGenome/GRCz11 -1 Tutorial1/Trimmed/Muscle_trimmed_R1.fastq.gz -2 Tutorial1/Trimmed/Muscle_trimmed_R2.fastq.gz -S Tutorial1/Mapped/Muscle.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada48bc8-6cb1-42dc-9a2c-d5ebad131495",
   "metadata": {},
   "source": [
    "In the next commands we'll convert the file to the more compressed [bam format](https://genome.ucsc.edu/goldenPath/help/bam.html) and sort the reads by chromosomal coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1fdfd-8251-4654-94db-c034215ef29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will convert to bam by using samtools view with the -b option. The h and S option tells samtools that the file has a header and is in sam format. We will pipe this to samtools sort. Pay attention to the \"-\" at the end of the sort command which tells samtools to use stdin.\n",
    "!samtools view -q 10 -bhS Tutorial1/Mapped/Liver.sam | samtools sort -o Tutorial1/Mapped/Liver.bam - \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab492ae-573f-423d-b24c-d8eb30352048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same thing for our Mutant sample.\n",
    "!samtools view -q 10 -bhS Tutorial1/Mapped/Muscle.sam | samtools sort -o Tutorial1/Mapped/Muscle.bam - \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b818b-c566-4e63-b30c-9f7a21c0925a",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 5: Removal of Duplicates\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d1981-f2e2-4d1a-b93c-b91ebed476eb",
   "metadata": {},
   "source": [
    "As with most of the other steps here, the duplicate removal step can be updated for the new data by changing the sample names in the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3625e7-740d-4553-b422-ef43d1f87049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take the sorted bam file and remove duplicates, saving a new bam file and a summary in a text file.\n",
    "!picard MarkDuplicates --REMOVE_DUPLICATES TRUE -I Tutorial1/Mapped/Liver.bam -O Tutorial1/Mapped/Liver_dedup.bam --METRICS_FILE Tutorial1/Mapped/Liver_dedup_metrics.txt --QUIET 2> Tutorial1/Mapped/PicardLog.txt\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5136f3-d0cc-4696-8ced-d5060cb4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also should do this for the other sample.\n",
    "!picard MarkDuplicates --REMOVE_DUPLICATES TRUE -I Tutorial1/Mapped/Muscle.bam -O Tutorial1/Mapped/Muscle_dedup.bam --METRICS_FILE Tutorial1/Mapped/Muscle_dedup_metrics.txt --QUIET 2> Tutorial1/Mapped/PicardLog2.txt\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9d7e8-d2c8-4074-bcc9-9b7bde4d10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use multiqc to summarize the metrics.\n",
    "!multiqc -o Tutorial1/QC -f Tutorial1/Mapped 2> Tutorial1/Mapped/multiqc_log.txt\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_general_stats.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25611c48-0c6a-4117-9229-5324933b47de",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"font-size:200%\">\n",
    "Great job! \n",
    "</div>\n",
    "\n",
    "That wraps up the preprocessing notebook on our new dataset. Overall, it is usually a matter of changing the commands to match the new filenames from the new data. Using this notebook as a guide, try to think through how you could update the others to run on the Liver and Muscle samples. \n",
    "\n",
    "Using the subsampled datasets, this tutorial should complete in about 10 minutes of runtime using the n1-standard-4 machine recommended by the module README file. Feel free to adjust the machine type and see how the runtime of different steps vary with more memory and compute resources. If you want to run the full dataset without subsampling, it would take a couple of hours using a n1-standard-64 machine.\n",
    "\n",
    "If you want to continue to adapt this for real-world data, you could also try to modify the notebooks to run on multiple samples. Currently, they rely on one case and one control sample, but in a real sequencing run you would likely have several samples of each. How could you modify the code here to handle that type of situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519e291-f42f-4f05-96d8-9241711a7faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
