{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3494e2-09a4-4688-9377-648fe84722e4",
   "metadata": {},
   "source": [
    "In this notebook, we are going to explore how to run this module with a new dataset. These submodules provide a great framework for running a rigorous and scalable ATAC-Seq analysis, but there are some considerations that must be made in order to run this with your own data. We will walk through that process here so that hopefully, you are able to take these notebooks to your research group and use them for your own analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc2106-27ba-4bd5-9cc6-9aed1024d615",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 1: Set Up Environment\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79377125-147a-458e-ba42-3aa9ed6693dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "!bash Mambaforge-$(uname)-$(uname -m).sh -b -p $HOME/mambaforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87bee4-7276-4c30-ac84-3b6f4af9e0ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "numthreads=!lscpu | grep '^CPU(s)'| awk '{print $2-1}'\n",
    "numthreadsint = int(numthreads[0])\n",
    "!~/mambaforge/bin/mamba install -c bioconda fastqc bowtie2 picard multiqc samtools trimmomatic -y\n",
    "!pip install jupyterquiz==2.0.7 jupytercards\n",
    "from jupyterquiz import display_quiz\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "from jupytercards import display_flashcards\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9079b2a-ae08-417e-9231-e78459e5ffe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add to your path\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/mambaforge/bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae2a63-1f7d-49ec-a919-c5954e906537",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 2: Get new fastq data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b0313-dbb9-4f0b-b6db-11f02ffe15ac",
   "metadata": {},
   "source": [
    "We are going to pull a new dataset from SRA. In this example, we are going to use data from an experiment that compared cis-regulatory elements across tissues in zebrafish. The BioProject ID is [PRJNA553572](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA553572). There are over 200 samples in this experiment, but for simplicity, we are only going to use one liver sample and one muscle sample. The accession numbers for these samples are SRR12173474 and SRR12173476. To learn how to pull data from SRA, we recommend you consult the [STRIDES tutorial on SRA downloads](https://github.com/STRIDES/NIHCloudLabGCP/blob/main/tutorials/notebooks/SRADownload/SRA-Download.ipynb). For this situation, we have already pulled the data from SRA and have it in our storage bucket, so we will copy it to our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa900e-e4b3-4239-b4d1-897c3977e071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These commands create our directory structure.\n",
    "!mkdir -p Tutorial1/InputFiles\n",
    "!mkdir -p Tutorial1/QC\n",
    "!mkdir -p Tutorial1/Trimmed\n",
    "!mkdir -p Tutorial1/Mapped\n",
    "!mkdir -p Tutorial1/RefGenome\n",
    "\n",
    "# These commands help identify the Google Cloud Storage bucket where the example files are held.\n",
    "original_bucket = \"gs://nigms-sandbox/unmc_atac_data_examples/Tutorial1\"\n",
    "\n",
    "# This command copies our example files to the Tutorial1/Inputfiles folder that we created above.\n",
    "!gsutil -m cp $original_bucket/InputFiles/Liver* Tutorial1/InputFiles/\n",
    "!gsutil -m cp $original_bucket/InputFiles/Muscle* Tutorial1/InputFiles/\n",
    "!gsutil -m cp $original_bucket/RefGenome/* Tutorial1/RefGenome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2385341-781e-47c1-a740-74e731809fb6",
   "metadata": {},
   "source": [
    "These are big fastq files, so we are using down-sampled versions that contain 10% of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a6725-8d17-42d3-9b83-99f166fd369b",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 3: QC\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f91cb-944a-43ae-b15c-25fc08b164e9",
   "metadata": {},
   "source": [
    "The next cell uses the wildcard \\*.fastq.gz to find the files so it does not need any changes to find our new data. We can run it normally below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83bd911-d188-46a9-82a2-a4e09d78fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command runs fastqc on each fastq.gz file inside our InputFiles directory and stores the ouput reports in our QC directory.\n",
    "!fastqc -t $numthreadsint -q -o Tutorial1/QC Tutorial1/InputFiles/*fastq.gz\n",
    "\n",
    "# We then use multiqc to summarize the report.\n",
    "!multiqc -o Tutorial1/QC -f Tutorial1/QC 2> Tutorial1/QC/multiqc_log.txt\n",
    "\n",
    "# We'll load this into a pandas table to work in this context, but fastqc also produces an html report that you can browse.\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_fastqc.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f6fa-f59f-4ed4-b5ec-ea10935bcdbe",
   "metadata": {},
   "source": [
    "As we come to the trimming step, we need to make some changes. As written, the notebook calls CTL and MUTANT, but our new samples are named Liver and Muslce. We will change the command to Liver and Muscle respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ed53f-d391-4077-954e-625464dfb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this cell, we have replaced CTL with Liver.\n",
    "\n",
    "# This will trim off N's as well as nextera adapters present in ATAC-seq library preparation. Placing the trimmed reads in our Trimmed folder.\n",
    "!trimmomatic PE -threads $numthreadsint Tutorial1/InputFiles/Liver_sub_1.fastq.gz Tutorial1/InputFiles/Liver_sub_2.fastq.gz Tutorial1/Trimmed/Liver_trimmed_R1.fastq.gz Tutorial1/Trimmed/Liver_unpaired_R1.fastq.gz Tutorial1/Trimmed/Liver_trimmed_R2.fastq.gz Tutorial1/Trimmed/Liver_unpaired_R2.fastq.gz ILLUMINACLIP:Tutorial1/RefGenome/NexteraPE.fa:2:30:10 LEADING:3 TRAILING:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f0191-68d9-4b0a-94ce-e601b9ce693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this cell, we have replaced MUTANT with Muscle.\n",
    "\n",
    "# This will trim off N's as well as nextera adapters present in ATAC-seq library preparation. Placing the trimmed reads in our Trimmed folder.\n",
    "!trimmomatic PE -threads $numthreadsint Tutorial1/InputFiles/Muscle_sub_1.fastq.gz Tutorial1/InputFiles/Muscle_sub_2.fastq.gz Tutorial1/Trimmed/Muscle_trimmed_R1.fastq.gz Tutorial1/Trimmed/Muscle_unpaired_R1.fastq.gz Tutorial1/Trimmed/Muscle_trimmed_R2.fastq.gz Tutorial1/Trimmed/Muscle_unpaired_R2.fastq.gz ILLUMINACLIP:Tutorial1/RefGenome/NexteraPE.fa:2:30:10 LEADING:3 TRAILING:3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f4abe-c217-46bf-b41d-0284efe57c9c",
   "metadata": {},
   "source": [
    "The summary step can proceed as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1d39e-4e92-4708-9fa2-dad49cbd3b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fastqc -t $numthreadsint -q -o Tutorial1/Trimmed Tutorial1/Trimmed/*fastq.gz\n",
    "!multiqc -o Tutorial1/QC -f Tutorial1/Trimmed 2> Tutorial1/QC/multiqc_log.txt\n",
    "\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_general_stats.txt\", sep='\\t')\n",
    "display(dframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c0ee9a-c08b-4530-a319-25e609464b1a",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 4: Mapping\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82294e-dad4-47f8-b44e-11d089d3d53d",
   "metadata": {},
   "source": [
    "The most important change we need to make in the mapping step is the reference genome. Our original notebook was based on human sequences, but our new dataset is comprised of zebrafish sequences. We will use the GRCz11 reference genome. We have already stored it in our storage bucket, but you can easily get bowtie2 reference genomes for several common organisms [here](https://benlangmead.github.io/aws-indexes/bowtie). Simply put the .bt2 files in your reference genome directory. We can confirm that we have downloaded them in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929031c-5489-4ad0-9db7-03e5b965acb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls Tutorial1/RefGenome/*bt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402b428-879e-4546-8e60-572c8bc3ed40",
   "metadata": {},
   "source": [
    "Next we will run the bowtie2 mapping step using the GRCz11 .bt2 reference files. As with above, we need to make the appropriate changes from CTL and MUTANT to our tissues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f2937-f9df-4cad-9b07-22265fad888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: The -x option specifies the prefix of the index. -1 specifies our left-end trimmed reads file. -2 specifies our right-end trimmed reads file. -S specifies our output file in sam format.\n",
    "!bowtie2 -p $numthreadsint -x Tutorial1/RefGenome/GRCz11 -1 Tutorial1/Trimmed/Liver_trimmed_R1.fastq.gz -2 Tutorial1/Trimmed/Liver_trimmed_R2.fastq.gz -S Tutorial1/Mapped/Liver.sam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fb88c-aa9e-435a-a4bf-f0774d6b1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same thing for our other sample.\n",
    "!bowtie2 -p $numthreadsint -x Tutorial1/RefGenome/GRCz11 -1 Tutorial1/Trimmed/Muscle_trimmed_R1.fastq.gz -2 Tutorial1/Trimmed/Muscle_trimmed_R2.fastq.gz -S Tutorial1/Mapped/Muscle.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada48bc8-6cb1-42dc-9a2c-d5ebad131495",
   "metadata": {},
   "source": [
    "In the next commands we'll convert the file to the more compressed [bam format](https://genome.ucsc.edu/goldenPath/help/bam.html) and sort the reads by chromosomal coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1fdfd-8251-4654-94db-c034215ef29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will convert to bam by using samtools view with the -b option. The h and S option tells samtools that the file has a header and is in sam format. We will pipe this to samtools sort. Pay attention to the \"-\" at the end of the sort command which tells samtools to use stdin.\n",
    "!samtools view -q 10 -bhS Tutorial1/Mapped/Liver.sam | samtools sort -o Tutorial1/Mapped/Liver.bam - \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab492ae-573f-423d-b24c-d8eb30352048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same thing for our Mutant sample.\n",
    "!samtools view -q 10 -bhS Tutorial1/Mapped/Muscle.sam | samtools sort -o Tutorial1/Mapped/Muscle.bam - \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b818b-c566-4e63-b30c-9f7a21c0925a",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"font-size:200%\">\n",
    "STEP 5: Removal of Duplicates\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d1981-f2e2-4d1a-b93c-b91ebed476eb",
   "metadata": {},
   "source": [
    "As with most of the other steps here, the duplicate removal step can be updated for the new data by changing the sample names in the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3625e7-740d-4553-b422-ef43d1f87049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take the sorted bam file and remove duplicates, saving a new bam file and a summary in a text file.\n",
    "!picard MarkDuplicates --REMOVE_DUPLICATES TRUE -I Tutorial1/Mapped/Liver.bam -O Tutorial1/Mapped/Liver_dedup.bam --METRICS_FILE Tutorial1/Mapped/Liver_dedup_metrics.txt --QUIET 2> Tutorial1/Mapped/PicardLog.txt\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5136f3-d0cc-4696-8ced-d5060cb4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also should do this for the other sample.\n",
    "!picard MarkDuplicates --REMOVE_DUPLICATES TRUE -I Tutorial1/Mapped/Muscle.bam -O Tutorial1/Mapped/Muscle_dedup.bam --METRICS_FILE Tutorial1/Mapped/Muscle_dedup_metrics.txt --QUIET 2> Tutorial1/Mapped/PicardLog2.txt\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9d7e8-d2c8-4074-bcc9-9b7bde4d10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use multiqc to summarize the metrics.\n",
    "!multiqc -o Tutorial1/QC -f Tutorial1/Mapped 2> Tutorial1/Mapped/multiqc_log.txt\n",
    "dframe = pd.read_csv(\"Tutorial1/QC/multiqc_data/multiqc_general_stats.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25611c48-0c6a-4117-9229-5324933b47de",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"font-size:200%\">\n",
    "Great job! \n",
    "</div>\n",
    "\n",
    "That wraps up the preprocessing notebook on our new dataset. Overall, it is usually a matter of changing the commands to match the new filenames from the new data. Using this notebook as a guide, try to think through how you could update the others to run on the Liver and Muscle samples. \n",
    "\n",
    "Using the subsampled datasets, this tutorial should complete in about 10 minutes of runtime using the n1-standard-4 machine recommended by the module README file. Feel free to adjust the machine type and see how the runtime of different steps vary with more memory and compute resources. If you want to run the full dataset without subsampling, it would take a couple of hours using a n1-standard-64 machine.\n",
    "\n",
    "If you want to continue to adapt this for real-world data, you could also try to modify the notebooks to run on multiple samples. Currently, they rely on one case and one control sample, but in a real sequencing run you would likely have several samples of each. How could you modify the code here to handle that type of situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519e291-f42f-4f05-96d8-9241711a7faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
